{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from itertools import combinations\n",
    "from scipy.stats import kendalltau\n",
    "from batchlog import BatchLogistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rc\n",
    "plt.style.use('seaborn')\n",
    "rc('text', usetex=False)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.NOTSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import scores from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_scores = pd.read_csv('https://raw.githubusercontent.com/dknguyengit/skate_predict/master/scores/trimmed_male.csv')\n",
    "female_scores = pd.read_csv('https://raw.githubusercontent.com/dknguyengit/skate_predict/master/scores/trimmed_female.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_male = male_scores.loc[male_scores['event']!='WR']\n",
    "world_male = male_scores.loc[male_scores['event']=='WR']\n",
    "season_female = female_scores.loc[female_scores['event']!='WR']\n",
    "world_female = female_scores.loc[female_scores['event']=='WR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2005, 2006, 2007, 2009, 2010, 2012, 2013, 2014, 2016, 2017],\n",
       " [2008, 2011, 2015, 2018])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_before_last = range(2005, 2018)\n",
    "year_seed = np.random.RandomState(seed=42)\n",
    "train_years = sorted(list(year_seed.choice(years_before_last, size=10, replace=False)))\n",
    "test_years = sorted([year for year in years_before_last if year not in train_years] + [2018])\n",
    "train_years, test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(scores, train_years, test_years):\n",
    "    season_scores = scores.loc[scores['event']!='WR']\n",
    "    world_scores = scores.loc[scores['event']=='WR']\n",
    "    \n",
    "    season_train = season_scores.loc[season_scores['year'].isin(train_years)]\n",
    "    world_train = world_scores.loc[world_scores['year'].isin(train_years)]\n",
    "    season_test = season_scores.loc[season_scores['year'].isin(test_years)]\n",
    "    world_test = world_scores.loc[world_scores['year'].isin(test_years)]    \n",
    "    \n",
    "    return season_train, world_train, season_test, world_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1216, 4), (238, 4), (507, 4), (96, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_train, world_train, season_test, world_test = train_test_split(male_scores, train_years, test_years)\n",
    "season_train.shape, world_train.shape, season_test.shape, world_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement kendall tau metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_ranking(skater_scores, world_scores):\n",
    "    skater_scores = skater_scores.sort_values(ascending=False)\n",
    "    world_scores = world_scores.sort_values(ascending=False)\n",
    "    skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "    world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "    return skater_ranking, world_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kendall_tau(skater_ranking, world_ranking, verbose=True):\n",
    "    skater_pairs = set(combinations(skater_ranking, 2))\n",
    "    world_pairs = set(combinations(world_ranking, 2))\n",
    "    n_pairs = len(skater_pairs)\n",
    "    n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "    if verbose:\n",
    "        print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "    tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "    return tau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yearly_scores(year, season_scores, world_scores):\n",
    "    yearly_season_scores = season_scores.loc[season_scores['year']==year].copy()\n",
    "    yearly_world_scores = world_scores.loc[world_scores['year']==year, ['name', 'score']].set_index('name').squeeze()\n",
    "    return yearly_season_scores, yearly_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores, world_scores = get_yearly_scores(2017, season_train, world_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize season scores by event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4C    24\n",
       "EU    24\n",
       "RU    12\n",
       "CA    12\n",
       "FR    11\n",
       "JP    11\n",
       "US    10\n",
       "CN    10\n",
       "FN     6\n",
       "Name: event, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_scores['event'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "grid = plt.GridSpec(4, 3, hspace=1.5, wspace=0.5)\n",
    "ax_box = fig.add_subplot(grid[:-1, :])\n",
    "ax_box = sns.boxplot(x='event', y='score', data=season_scores, ax=ax_box)\n",
    "ax_box.set_xlabel('Event')\n",
    "ax_box.set_ylabel('Score')\n",
    "\n",
    "ax_label1 = fig.add_subplot(grid[-1, 0])\n",
    "ax_label2 = fig.add_subplot(grid[-1, 1])\n",
    "ax_label3 = fig.add_subplot(grid[-1, 2])\n",
    "\n",
    "for ax in [ax_label1, ax_label2, ax_label3]:\n",
    "    ax.set_facecolor('white')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "ax_label1.text(0, 1, s='US: USA\\nCA: Canada\\nFR: France',\n",
    "               verticalalignment='top',\n",
    "               transform=ax_label1.transAxes)\n",
    "ax_label2.text(0, 1, s='RU: Russia\\nCN: China\\nJP: Japan',\n",
    "               verticalalignment='top',\n",
    "               transform=ax_label2.transAxes)\n",
    "ax_label3.text(0, 1, s='FN: Grand Prix Final\\nEU: European\\n4C: 4 Continent',\n",
    "               verticalalignment='top',\n",
    "               transform=ax_label3.transAxes)\n",
    "# ax.get_figure().savefig('2017_score_dist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average skate score model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        290.5350\n",
       "Javier, FERNANDEZ    285.4925\n",
       "Shoma, UNO           283.7425\n",
       "Nathan, CHEN         281.0050\n",
       "Patrick, CHAN        270.3500\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_avg = season_scores.groupby('name')['score'].mean().sort_values(ascending=False)\n",
    "season_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 234 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6956521739130435"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_ranking, world_ranking = return_ranking(season_avg, world_scores)\n",
    "calculate_kendall_tau(avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result agrees with kendalltau from scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KendalltauResult(correlation=0.6956521739130435, pvalue=1.9126097800691154e-06)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_numeric_rank = list(range(len(avg_ranking)))\n",
    "world_numeric_rank = [avg_ranking.index(skater) for skater in world_ranking]\n",
    "kendalltau(season_numeric_rank, world_numeric_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE with mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.271546837961868"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_comparison = pd.merge(season_scores, season_avg.to_frame(), left_on='name', right_index=True, suffixes=['', '_avg'])\n",
    "score_comparison['sq_error'] = (score_comparison['score'] - score_comparison['score_avg'])**2\n",
    "np.sqrt(score_comparison['sq_error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.skater_scores = None\n",
    "        self.model_ranking = None\n",
    "        self.world_ranking = None\n",
    "        self.predicted_season_scores = None\n",
    "    \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        squared_errors = (season_scores['score'].values - self.predicted_season_scores)**2\n",
    "        rmse = np.sqrt(squared_errors.mean())\n",
    "        return rmse\n",
    "        \n",
    "    def evaluate_kendall_tau(self, world_scores, verbose=True):\n",
    "        def return_ranking(skater_scores, world_scores):\n",
    "            skater_scores = skater_scores.sort_values(ascending=False)\n",
    "            world_scores = world_scores.sort_values(ascending=False)\n",
    "            skater_ranking = list(skater_scores.index.intersection(world_scores.index))\n",
    "            world_ranking = list(world_scores.index.intersection(skater_scores.index))\n",
    "            return skater_ranking, world_ranking\n",
    "    \n",
    "        def calculate_kendall_tau(skater_ranking, world_ranking, verbose=verbose):\n",
    "            skater_pairs = set(combinations(skater_ranking, 2))\n",
    "            world_pairs = set(combinations(world_ranking, 2))\n",
    "            n_pairs = len(skater_pairs)\n",
    "            n_concordant_pairs = len(set(skater_pairs) & set(world_pairs))\n",
    "            if verbose:\n",
    "                print(f'There are {n_concordant_pairs} concordant_pairs out of {n_pairs} pairs')\n",
    "            tau = (2 * n_concordant_pairs - n_pairs) / n_pairs\n",
    "            return tau, n_concordant_pairs, n_pairs\n",
    "        \n",
    "        skater_scores = self.skater_scores.squeeze()\n",
    "        self.model_ranking, self.world_ranking = return_ranking(skater_scores, world_scores)\n",
    "        return calculate_kendall_tau(self.model_ranking, self.world_ranking)\n",
    "    \n",
    "    def evaluate_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        taus = []\n",
    "        rmses = []\n",
    "        concordant_pairs = []\n",
    "        n_pairs = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            tau, concordant_pair, n_pair = self.evaluate_kendall_tau(world_scores, verbose=False)\n",
    "            \n",
    "            rmses.append(rmse)\n",
    "            taus.append(tau)\n",
    "            concordant_pairs.append(concordant_pair)\n",
    "            n_pairs.append(n_pair)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses, \n",
    "                             'tau': taus, 'conc': concordant_pairs, 'pairs': n_pairs}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        self.predicted_season_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "    \n",
    "    def fit(self, season_scores):\n",
    "        self.skater_scores = season_scores.groupby('name')['score'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.predict_season_scores(season_scores)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = AverageScore()\n",
    "avg_train_eval = avg.evaluate_over_years(train_years, season_train, world_train)\n",
    "avg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "season_scores['score_normed'] = season_scores.groupby('event')['score'].transform(lambda score: (score - score.mean()) / score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "Yuzuru, HANYU        1.668135\n",
       "Javier, FERNANDEZ    1.440927\n",
       "Shoma, UNO           1.326910\n",
       "Nathan, CHEN         1.104096\n",
       "Patrick, CHAN        1.090843\n",
       "Name: score_normed, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_normed_avg = season_scores.groupby('name')['score_normed'].mean().sort_values(ascending=False)\n",
    "season_normed_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 222 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6086956521739131"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_avg_ranking, world_ranking = return_ranking(season_normed_avg, world_scores)\n",
    "calculate_kendall_tau(normed_avg_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedAverageScore(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def predict_season_scores(self, season_scores, event_stds, event_means):\n",
    "        self.predicted_season_scores = (self.skater_scores.loc[season_scores['name']] * event_stds + event_means).values\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        season_scores = season_scores.copy()\n",
    "        event_means = season_scores.groupby('event')['score'].mean().loc[season_scores['event']].values\n",
    "        event_stds = season_scores.groupby('event')['score'].std().loc[season_scores['event']].values\n",
    "        season_scores['score_normed'] = (season_scores['score'] - event_means) / event_stds\n",
    "        \n",
    "        self.skater_scores = season_scores.groupby('name')['score_normed'].mean()\n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores, event_stds, event_means)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Stephane, LAMBIEL</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>262.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Jeffrey, BUTTLE</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>245.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Evan, LYSACEK</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>239.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Johnny, WEIR</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>236.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Chengjiang, LI</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>235.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Brian, JOUBERT</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>235.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Emanuel, SANDHU</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>231.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Kevin, VAN DER PERREN</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>229.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Frederic, DAMBIER</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>226.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Timothy, GOEBEL</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>222.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Andrei, GRIAZEV</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>216.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Stefan, LINDEMANN</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>213.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Ivan, DINEV</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>213.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Kristoffer, BERNTSSON</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>211.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Daisuke, TAKAHASHI</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>210.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Min, ZHANG</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>208.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Sergei, DOBRIN</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>207.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Gheorghe, CHIPER</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>199.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Roman, SEROV</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>191.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Karel, ZELENKA</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>189.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Jamal, OTHMAN</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>186.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Sergei, DAVYDOV</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>178.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Viktor, PFEIFER</td>\n",
       "      <td>2005</td>\n",
       "      <td>WR</td>\n",
       "      <td>178.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Stephane, LAMBIEL</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>274.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Brian, JOUBERT</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>270.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Evan, LYSACEK</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>255.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Nobunari, ODA</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>251.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Emanuel, SANDHU</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>249.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Jeffrey, BUTTLE</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>241.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Johnny, WEIR</td>\n",
       "      <td>2006</td>\n",
       "      <td>WR</td>\n",
       "      <td>235.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>Michael Christian, MARTINEZ</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>204.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>Chafik, BESSEGHIER</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>203.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>Julian Zhi Jie, YEE</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>202.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>Phillip, HARRIS</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>190.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1741</th>\n",
       "      <td>Ivan, PAVLOV</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>178.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>June Hyoung, LEE</td>\n",
       "      <td>2016</td>\n",
       "      <td>WR</td>\n",
       "      <td>174.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>Yuzuru, HANYU</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>321.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>Shoma, UNO</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>319.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>Boyang, JIN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>303.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>Javier, FERNANDEZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>301.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>Patrick, CHAN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>295.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>Nathan, CHEN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>290.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>Jason, BROWN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>269.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>Mikhail, KOLYADA</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>257.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>Kevin, REYNOLDS</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>253.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>Alexei, BYCHENKO</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>245.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>Maxim, KOVTUN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>245.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>Misha, GE</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>243.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>Moris, KVITELASHVILI</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>239.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>Deniss, VASILJEVS</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>239.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>Brendan, KERRY</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>236.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>Denis, TEN</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>234.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>Chafik, BESSEGHIER</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>230.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>Michal, BREZINA</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>226.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>Keiji, TANAKA</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>222.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>Paul, FENTZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>217.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>Jorik, HENDRICKX</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>214.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>Julian Zhi Jie, YEE</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>213.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>Alexander, MAJOROV</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>205.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>Michael Christian, MARTINEZ</td>\n",
       "      <td>2017</td>\n",
       "      <td>WR</td>\n",
       "      <td>196.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  year event   score\n",
       "120             Stephane, LAMBIEL  2005    WR  262.46\n",
       "121               Jeffrey, BUTTLE  2005    WR  245.69\n",
       "122                 Evan, LYSACEK  2005    WR  239.29\n",
       "123                  Johnny, WEIR  2005    WR  236.06\n",
       "124                Chengjiang, LI  2005    WR  235.67\n",
       "125                Brian, JOUBERT  2005    WR  235.29\n",
       "126               Emanuel, SANDHU  2005    WR  231.16\n",
       "127         Kevin, VAN DER PERREN  2005    WR  229.94\n",
       "128             Frederic, DAMBIER  2005    WR  226.88\n",
       "129               Timothy, GOEBEL  2005    WR  222.57\n",
       "130               Andrei, GRIAZEV  2005    WR  216.62\n",
       "131             Stefan, LINDEMANN  2005    WR  213.54\n",
       "132                   Ivan, DINEV  2005    WR  213.09\n",
       "133         Kristoffer, BERNTSSON  2005    WR  211.97\n",
       "134            Daisuke, TAKAHASHI  2005    WR  210.35\n",
       "135                    Min, ZHANG  2005    WR  208.10\n",
       "136                Sergei, DOBRIN  2005    WR  207.20\n",
       "137              Gheorghe, CHIPER  2005    WR  199.18\n",
       "138                  Roman, SEROV  2005    WR  191.21\n",
       "139                Karel, ZELENKA  2005    WR  189.67\n",
       "140                 Jamal, OTHMAN  2005    WR  186.48\n",
       "141               Sergei, DAVYDOV  2005    WR  178.73\n",
       "142               Viktor, PFEIFER  2005    WR  178.06\n",
       "289             Stephane, LAMBIEL  2006    WR  274.22\n",
       "290                Brian, JOUBERT  2006    WR  270.83\n",
       "291                 Evan, LYSACEK  2006    WR  255.22\n",
       "292                 Nobunari, ODA  2006    WR  251.21\n",
       "293               Emanuel, SANDHU  2006    WR  249.89\n",
       "294               Jeffrey, BUTTLE  2006    WR  241.59\n",
       "295                  Johnny, WEIR  2006    WR  235.57\n",
       "...                           ...   ...   ...     ...\n",
       "1737  Michael Christian, MARTINEZ  2016    WR  204.10\n",
       "1738           Chafik, BESSEGHIER  2016    WR  203.20\n",
       "1739          Julian Zhi Jie, YEE  2016    WR  202.94\n",
       "1740              Phillip, HARRIS  2016    WR  190.42\n",
       "1741                 Ivan, PAVLOV  2016    WR  178.89\n",
       "1742             June Hyoung, LEE  2016    WR  174.88\n",
       "1863                Yuzuru, HANYU  2017    WR  321.59\n",
       "1864                   Shoma, UNO  2017    WR  319.31\n",
       "1865                  Boyang, JIN  2017    WR  303.58\n",
       "1866            Javier, FERNANDEZ  2017    WR  301.19\n",
       "1867                Patrick, CHAN  2017    WR  295.16\n",
       "1868                 Nathan, CHEN  2017    WR  290.72\n",
       "1869                 Jason, BROWN  2017    WR  269.57\n",
       "1870             Mikhail, KOLYADA  2017    WR  257.47\n",
       "1871              Kevin, REYNOLDS  2017    WR  253.84\n",
       "1872             Alexei, BYCHENKO  2017    WR  245.96\n",
       "1873                Maxim, KOVTUN  2017    WR  245.84\n",
       "1874                    Misha, GE  2017    WR  243.45\n",
       "1875         Moris, KVITELASHVILI  2017    WR  239.24\n",
       "1876            Deniss, VASILJEVS  2017    WR  239.00\n",
       "1877               Brendan, KERRY  2017    WR  236.24\n",
       "1878                   Denis, TEN  2017    WR  234.31\n",
       "1879           Chafik, BESSEGHIER  2017    WR  230.13\n",
       "1880              Michal, BREZINA  2017    WR  226.26\n",
       "1881                Keiji, TANAKA  2017    WR  222.34\n",
       "1882                  Paul, FENTZ  2017    WR  217.91\n",
       "1883             Jorik, HENDRICKX  2017    WR  214.02\n",
       "1884          Julian Zhi Jie, YEE  2017    WR  213.99\n",
       "1885           Alexander, MAJOROV  2017    WR  205.04\n",
       "1886  Michael Christian, MARTINEZ  2017    WR  196.79\n",
       "\n",
       "[238 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>14.221490</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>166</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>12.650485</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>12.556444</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>14.067104</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.898410</td>\n",
       "      <td>0.593074</td>\n",
       "      <td>184</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.437599</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>15.373393</td>\n",
       "      <td>0.494071</td>\n",
       "      <td>189</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>15.685363</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>177</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>18.328151</td>\n",
       "      <td>0.615942</td>\n",
       "      <td>223</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>15.921112</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>222</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  14.221490  0.580952   166    210\n",
       "1  2006  12.650485  0.636364   207    253\n",
       "2  2007  12.556444  0.630435   225    276\n",
       "3  2009  14.067104  0.615942   223    276\n",
       "4  2010  12.898410  0.593074   184    231\n",
       "5  2012  12.437599  0.494071   189    253\n",
       "6  2013  15.373393  0.494071   189    253\n",
       "7  2014  15.685363  0.685714   177    210\n",
       "8  2016  18.328151  0.615942   223    276\n",
       "9  2017  15.921112  0.608696   222    276"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normavg = NormedAverageScore()\n",
    "normavg_train_eval = normavg.evaluate_over_years(train_years, season_train, world_train)\n",
    "normavg_train_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "season_scores = season_train.loc[season_train['year']==year].copy()\n",
    "world_scores = world_train.loc[world_train['year']==year, ['name', 'score']].set_index('name').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "unique_skaters = season_scores['name'].unique()\n",
    "unique_events = season_scores['event'].unique()\n",
    "\n",
    "dummies_skater_count = len(unique_skaters) - 1\n",
    "dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "dropped_event = list(set(unique_events) - set(dummies_events))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "        -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "        -45.88750626,  -35.41149857])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dummies.values\n",
    "X = np.insert(X, 0, 1, axis=1)\n",
    "y = season_scores['score'].values\n",
    "coefs_linear = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
    "coefs_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_rmse = np.sqrt(np.mean((y - X @ coefs_linear)**2))\n",
    "linear_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 262.83064921,  -58.77196129,  -27.74060019,  -38.56497213,\n",
       "         -16.6525816 , -100.78064921,  -36.58476179,    3.9048582 ,\n",
       "         -45.88750626,  -35.41149857]), 0.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, y)\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.838699611397724"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y, X @ lin.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropped baseline skater and event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Model):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__()\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.event_scores = None\n",
    "        self.baseline = None\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ y)\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        \n",
    "    def fit(self, season_scores):\n",
    "        dummies = pd.get_dummies(season_scores[['name', 'event']], prefix=['', ''], prefix_sep='', drop_first=True)\n",
    "        unique_skaters = season_scores['name'].unique()\n",
    "        unique_events = season_scores['event'].unique()\n",
    "        \n",
    "        dummies_skater_count = len(unique_skaters) - 1\n",
    "        dummies_skaters = dummies.columns[:dummies_skater_count]\n",
    "        dummies_events = dummies.columns[dummies_skater_count:]\n",
    "\n",
    "        dropped_skater = list(set(unique_skaters) - set(dummies_skaters))[0]\n",
    "        dropped_event = list(set(unique_events) - set(dummies_events))[0]\n",
    "\n",
    "        X = dummies.values\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        y = season_scores['score'].values\n",
    "        coefs = self.find_coefs(X, y)\n",
    "\n",
    "        self.baseline = coefs[0]    \n",
    "        self.skater_scores = pd.Series(coefs[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "        self.event_scores = pd.Series(coefs[dummies_skater_count+1:], index=dummies_events)\n",
    "        self.skater_scores[dropped_skater] = 0\n",
    "        self.event_scores[dropped_event] = 0\n",
    "        \n",
    "        self.skater_scores.sort_values(ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(ascending=False, inplace=True)        \n",
    "        \n",
    "        self.predict_season_scores(season_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>8.555327</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>7.883763</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.578146</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.110917</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>219</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>9.798364</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>196</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.144647</td>\n",
       "      <td>0.541502</td>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.047367</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>8.781486</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>190</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.053367</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>8.838700</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   8.555327  0.666667   175    210\n",
       "1  2006   7.883763  0.620553   205    253\n",
       "2  2007   7.578146  0.601449   221    276\n",
       "3  2009   8.110917  0.586957   219    276\n",
       "4  2010   9.798364  0.696970   196    231\n",
       "5  2012   8.144647  0.541502   195    253\n",
       "6  2013   9.047367  0.691700   214    253\n",
       "7  2014   8.781486  0.809524   190    210\n",
       "8  2016  11.053367  0.673913   231    276\n",
       "9  2017   8.838700  0.731884   239    276"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = Linear()\n",
    "linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "linear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.662111801242236"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.779208324854647 0.662111801242236\n",
      "0.001 8.782755125399937 0.6619499341238472\n",
      "0.01 8.925173433616132 0.6596894409937888\n",
      "0.1 9.788140496081605 0.6537982307547525\n",
      "1 15.206034467688387 0.637331074722379\n",
      "10 27.042844923858063 0.6193073593073594\n",
      "100 32.34814733209342 0.6250574063617542\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    linear = Linear(lambda_reg=lambda_reg)\n",
    "    linear_train_eval = linear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, linear_train_eval['rmse'].mean(), linear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "       -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_log_linear = np.linalg.inv(X.T @ X) @ (X.T @ np.log(y))\n",
    "coefs_log_linear[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_linear_rmse = np.exp(np.sqrt(np.mean((np.log(y) - X @ coefs_log_linear)**2)))\n",
    "log_linear_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "skater_scores = pd.Series(coefs_log_linear[1:dummies_skater_count+1], index=dummies_skaters)\n",
    "event_scores = pd.Series(coefs_log_linear[dummies_skater_count+1:], index=dummies_events)\n",
    "\n",
    "skater_scores[dropped_skater] = 0\n",
    "event_scores[dropped_skater] = 0\n",
    "\n",
    "skater_scores.sort_values(ascending=False, inplace=True)\n",
    "event_scores.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "skater_scores = np.exp(skater_scores)\n",
    "event_scores = np.exp(event_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  1.154228\n",
       "Nathan, CHEN                   1.110905\n",
       "Javier, FERNANDEZ              1.108103\n",
       "Shoma, UNO                     1.105957\n",
       "Patrick, CHAN                  1.062009\n",
       "Denis, TEN                     1.059121\n",
       "Boyang, JIN                    1.014664\n",
       "Adam, RIPPON                   1.000000\n",
       "Jason, BROWN                   0.953747\n",
       "Sergei, VORONOV                0.947786\n",
       "Alexei, BYCHENKO               0.937530\n",
       "Mikhail, KOLYADA               0.933023\n",
       "Takahito, MURA                 0.932946\n",
       "Max, AARON                     0.928603\n",
       "Kevin, REYNOLDS                0.912023\n",
       "Maxim, KOVTUN                  0.911407\n",
       "Misha, GE                      0.906351\n",
       "Keiji, TANAKA                  0.905789\n",
       "Nam, NGUYEN                    0.898441\n",
       "Alexander, PETROV              0.892819\n",
       "Jorik, HENDRICKX               0.891376\n",
       "Moris, KVITELASHVILI           0.880480\n",
       "Timothy, DOLENSKY              0.877638\n",
       "Han, YAN                       0.875485\n",
       "Gordei, GORSHKOV               0.869104\n",
       "Daniel, SAMOHIN                0.867256\n",
       "Chafik, BESSEGHIER             0.865572\n",
       "Artur, DMITRIEV                0.860806\n",
       "Deniss, VASILJEVS              0.856720\n",
       "Alexander, SAMARIN             0.853385\n",
       "                                 ...   \n",
       "Michal, BREZINA                0.841853\n",
       "Elladj, BALDE                  0.835828\n",
       "Paul, FENTZ                    0.834829\n",
       "Grant, HOCHSTEIN               0.831686\n",
       "Brendan, KERRY                 0.822836\n",
       "Michael Christian, MARTINEZ    0.815368\n",
       "Ross, MINER                    0.807469\n",
       "Alexander, MAJOROV             0.775878\n",
       "Julian Zhi Jie, YEE            0.771658\n",
       "Ivan, RIGHINI                  0.753486\n",
       "Ivan, PAVLOV                   0.749886\n",
       "Sihyeong, LEE                  0.745196\n",
       "Jinseo, KIM                    0.742645\n",
       "Kevin, AYMOZ                   0.737319\n",
       "Graham, NEWBERRY               0.732107\n",
       "Stephane, WALKER               0.727227\n",
       "Javier, RAYA                   0.722792\n",
       "June Hyoung, LEE               0.714204\n",
       "Maurizio, ZANDRON              0.689007\n",
       "Jiri, BELOHRADSKY              0.671338\n",
       "Slavik, HAYRAPETYAN            0.668233\n",
       "Daniel Albert, NAURITS         0.650934\n",
       "Chih-I, TSAO                   0.645860\n",
       "Andrew, DODDS                  0.616999\n",
       "Mark, WEBSTER                  0.609308\n",
       "Valtter, VIRTANEN              0.606540\n",
       "Sondre, ODDVOLL BOE            0.601957\n",
       "Leslie, IP                     0.558707\n",
       "Kai Xiang, CHEW                0.527181\n",
       "Micah, TANG                    0.517015\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skater_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check with sklearn's LinearRegression and mean_square_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.57079276, -0.2537603 , -0.11337176, -0.15854428, -0.06450661,\n",
       "        -0.48288783, -0.14988655,  0.01455732, -0.19499875, -0.14436472]), 0.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, np.log(y))\n",
    "lin.coef_[:10], lin.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0376683361937684"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.sqrt(mean_squared_error(np.log(y), X @ lin.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Kendall's Tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_linear_ranking, world_ranking = return_ranking(skater_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 239 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7318840579710145"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(linear_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogLinear(Linear):\n",
    "    def __init__(self, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        \n",
    "    def find_coefs(self, X, y):\n",
    "        L = np.identity(n=len(X.T))\n",
    "        L[0, 0] = 0\n",
    "        coefs = np.linalg.inv(X.T @ X + self.lambda_reg * L) @ (X.T @ np.log(y))\n",
    "        return coefs\n",
    "    \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        broadcasted_skater_scores = self.skater_scores.loc[season_scores['name']].values\n",
    "        broadcasted_event_scores = self.event_scores.loc[season_scores['event']].values\n",
    "        self.log_predicted_season_scores = broadcasted_skater_scores + broadcasted_event_scores + self.baseline\n",
    "        self.predicted_season_scores = np.exp(self.log_predicted_season_scores)\n",
    "        \n",
    "    def evaluate_rmse(self, season_scores):\n",
    "        log_squared_errors = (np.log(season_scores['score'].values) - self.log_predicted_season_scores)**2\n",
    "        log_rmse = np.sqrt(log_squared_errors.mean())\n",
    "        rmse = np.exp(log_rmse)\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>1.051008</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>175</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>1.045100</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>207</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>1.042015</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1.042605</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>216</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1.050437</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>1.040119</td>\n",
       "      <td>0.525692</td>\n",
       "      <td>193</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>1.041869</td>\n",
       "      <td>0.683794</td>\n",
       "      <td>213</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>1.040164</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>1.048652</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>231</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>1.037668</td>\n",
       "      <td>0.731884</td>\n",
       "      <td>239</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year      rmse       tau  conc  pairs\n",
       "0  2005  1.051008  0.666667   175    210\n",
       "1  2006  1.045100  0.636364   207    253\n",
       "2  2007  1.042015  0.601449   221    276\n",
       "3  2009  1.042605  0.565217   216    276\n",
       "4  2010  1.050437  0.714286   198    231\n",
       "5  2012  1.040119  0.525692   193    253\n",
       "6  2013  1.041869  0.683794   213    253\n",
       "7  2014  1.040164  0.828571   192    210\n",
       "8  2016  1.048652  0.673913   231    276\n",
       "9  2017  1.037668  0.731884   239    276"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear = LogLinear()\n",
    "loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "loglinear_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6627837380011293"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglinear_train_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>10.357050</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>173</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.749220</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>214</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>8.151442</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>225</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.557905</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>11.139947</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>198</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>9.424702</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.965307</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>203</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>10.563519</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>191</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>12.694622</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>10.271547</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>234</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005  10.357050  0.647619   173    210\n",
       "1  2006   9.749220  0.691700   214    253\n",
       "2  2007   8.151442  0.630435   225    276\n",
       "3  2009   8.557905  0.601449   221    276\n",
       "4  2010  11.139947  0.714286   198    231\n",
       "5  2012   9.424702  0.604743   203    253\n",
       "6  2013   9.965307  0.604743   203    253\n",
       "7  2014  10.563519  0.819048   191    210\n",
       "8  2016  12.694622  0.695652   234    276\n",
       "9  2017  10.271547  0.695652   234    276"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg.evaluate_over_years(train_years, season_train, world_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.043963617896676 0.6627837380011293\n",
      "0.001 1.043998390360219 0.6618520609824958\n",
      "0.01 1.0453133728174064 0.653425559947299\n",
      "0.1 1.0518538623368006 0.6394089968003012\n",
      "1 1.087499139738013 0.6379691323169585\n",
      "10 1.162036606713829 0.6258008658008658\n",
      "100 1.1945282438818492 0.6286598908338039\n"
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    loglinear = LogLinear(lambda_reg=lambda_reg)\n",
    "    loglinear_train_eval = loglinear.evaluate_over_years(train_years, season_train, world_train)\n",
    "    print(lambda_reg, loglinear_train_eval['rmse'].mean(), loglinear_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "skater_names = list(season_table.index)\n",
    "event_names = list(season_table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_scores = season_table.values\n",
    "skater_scores = np.full(len(skater_names), 0.5)\n",
    "event_scores = np.full(len(event_names), 0.5)\n",
    "bias = 0.5\n",
    "\n",
    "alpha = 0.001\n",
    "rmses = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    diff = np.outer(skater_scores, event_scores) + bias - true_scores\n",
    "    skater_gradients = np.nansum(diff * event_scores, axis=1)\n",
    "    event_gradients = np.nansum(diff.T * skater_scores, axis=1)\n",
    "    bias_gradient = np.nansum(diff)\n",
    "    \n",
    "    event_scores = event_scores - alpha * event_gradients\n",
    "    skater_scores = skater_scores - alpha * skater_gradients\n",
    "    bias = bias - alpha * bias_gradient\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    rmses.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.863043830654695"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f590e1f0d30>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yuzuru, HANYU                  11.368899\n",
       "Nathan, CHEN                   10.696464\n",
       "Javier, FERNANDEZ              10.567736\n",
       "Shoma, UNO                     10.562198\n",
       "Patrick, CHAN                   9.981089\n",
       "Denis, TEN                      9.937335\n",
       "Boyang, JIN                     9.312272\n",
       "Adam, RIPPON                    9.098090\n",
       "Jason, BROWN                    8.460356\n",
       "Sergei, VORONOV                 8.312755\n",
       "Takahito, MURA                  8.193166\n",
       "Alexei, BYCHENKO                8.080860\n",
       "Mikhail, KOLYADA                8.037651\n",
       "Max, AARON                      7.963655\n",
       "Maxim, KOVTUN                   7.855620\n",
       "Kevin, REYNOLDS                 7.832711\n",
       "Misha, GE                       7.763226\n",
       "Keiji, TANAKA                   7.620523\n",
       "Nam, NGUYEN                     7.619910\n",
       "Alexander, PETROV               7.541744\n",
       "Jorik, HENDRICKX                7.515032\n",
       "Moris, KVITELASHVILI            7.359118\n",
       "Timothy, DOLENSKY               7.334442\n",
       "Han, YAN                        7.329392\n",
       "Daniel, SAMOHIN                 7.153315\n",
       "Chafik, BESSEGHIER              7.084044\n",
       "Gordei, GORSHKOV                7.077550\n",
       "Artur, DMITRIEV                 7.000995\n",
       "Alexander, SAMARIN              6.979732\n",
       "Deniss, VASILJEVS               6.937469\n",
       "                                 ...    \n",
       "Paul, FENTZ                     6.719907\n",
       "Grant, HOCHSTEIN                6.708263\n",
       "Ryuju, HINO                     6.703980\n",
       "Elladj, BALDE                   6.637348\n",
       "Brendan, KERRY                  6.556827\n",
       "Michael Christian, MARTINEZ     6.451284\n",
       "Ross, MINER                     6.314202\n",
       "Alexander, MAJOROV              5.858490\n",
       "Julian Zhi Jie, YEE             5.824359\n",
       "Ivan, RIGHINI                   5.567713\n",
       "Ivan, PAVLOV                    5.530509\n",
       "Sihyeong, LEE                   5.444818\n",
       "Jinseo, KIM                     5.408229\n",
       "Kevin, AYMOZ                    5.354532\n",
       "Graham, NEWBERRY                5.281554\n",
       "Stephane, WALKER                5.213233\n",
       "Javier, RAYA                    5.151124\n",
       "June Hyoung, LEE                5.000291\n",
       "Maurizio, ZANDRON               4.678056\n",
       "Jiri, BELOHRADSKY               4.430653\n",
       "Slavik, HAYRAPETYAN             4.387176\n",
       "Daniel Albert, NAURITS          4.144949\n",
       "Chih-I, TSAO                    4.020037\n",
       "Andrew, DODDS                   3.606092\n",
       "Valtter, VIRTANEN               3.523336\n",
       "Mark, WEBSTER                   3.495779\n",
       "Sondre, ODDVOLL BOE             3.459157\n",
       "Leslie, IP                      2.770009\n",
       "Kai Xiang, CHEW                 2.317837\n",
       "Micah, TANG                     2.172027\n",
       "Length: 62, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_scores = pd.Series(skater_scores, index=skater_names)\n",
    "hybrid_scores.sort_values(ascending=False, inplace=True)\n",
    "hybrid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_ranking, world_ranking = return_ranking(hybrid_scores, world_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 238 concordant_pairs out of 276 pairs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7246376811594203"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_kendall_tau(hybrid_ranking, world_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(Linear):\n",
    "    def __init__(self, alpha, n_factors, lambda_reg=0):\n",
    "        super().__init__(lambda_reg)\n",
    "        self.alpha = alpha\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "    def predict_season_scores(self, season_scores):\n",
    "        predicted_score_table = pd.DataFrame(self.skater_scores.values @ self.event_scores.values.T + self.baseline,\n",
    "                                            index=self.skater_scores.index,\n",
    "                                            columns=self.event_scores.index)\n",
    "        \n",
    "        predicted_score_stacked = predicted_score_table.stack()\n",
    "        season_skater_event_index = season_scores.set_index(['name', 'event']).index\n",
    "        self.predicted_season_scores = predicted_score_stacked.loc[season_skater_event_index].values\n",
    "        \n",
    "    def fit(self, season_scores, n_iter, seed=42, fixed_baseline=False, verbose=False):\n",
    "        if verbose:\n",
    "            logging.disable(logging.NOTSET)\n",
    "        else:\n",
    "            logging.disable(logging.DEBUG)\n",
    "        season_table = pd.pivot_table(season_scores[['name', 'event', 'score']], values='score', index='name', columns='event')\n",
    "        skater_names = list(season_table.index)\n",
    "        event_names = list(season_table.columns)\n",
    "\n",
    "        true_scores = season_table.values\n",
    "        random_state = np.random.RandomState(seed=seed)\n",
    "        self.skater_scores = random_state.random_sample((len(skater_names), self.n_factors))\n",
    "        self.event_scores = random_state.random_sample((len(event_names), self.n_factors))\n",
    "        self.baseline = season_scores['score'].mean() if fixed_baseline else 0.5\n",
    "\n",
    "        self.rmses = []\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            logging.debug(f'iteration: {iteration}')\n",
    "            diff = self.skater_scores @ self.event_scores.T + self.baseline - true_scores\n",
    "            \n",
    "            for i in range(self.n_factors):\n",
    "                logging.debug(f'i: {i}')\n",
    "                if not fixed_baseline:\n",
    "                    baseline_gradient = np.nansum(diff)\n",
    "                    self.baseline = self.baseline - self.alpha * baseline_gradient\n",
    "                    \n",
    "                logging.debug(f'skater_scores before\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores before\\n{self.event_scores}')                               \n",
    "                skater_gradients = np.nansum(diff * self.event_scores[:, i], axis=1) + self.lambda_reg * self.skater_scores[:, i]\n",
    "                event_gradients = np.nansum(diff.T * self.skater_scores[:, i], axis=1) + self.lambda_reg * self.event_scores[:, i] \n",
    "                logging.debug(f'skater_gradients\\n{skater_gradients}')\n",
    "                logging.debug(f'event_gradients\\n{event_gradients}')\n",
    "                \n",
    "                self.skater_scores[:, i] = self.skater_scores[:, i] - self.alpha * skater_gradients\n",
    "                self.event_scores[:, i] = self.event_scores[:, i] - self.alpha * event_gradients\n",
    "                logging.debug(f'skater_scores after\\n{self.skater_scores}')\n",
    "                logging.debug(f'event_scores after\\n{self.event_scores}')\n",
    "                \n",
    "            rmse = np.sqrt(np.nanmean(diff**2))\n",
    "            self.rmses.append(rmse)\n",
    "\n",
    "        self.skater_scores = pd.DataFrame(self.skater_scores, index=skater_names)\n",
    "        self.event_scores = pd.DataFrame(self.event_scores, index=event_names)\n",
    "        \n",
    "        self.skater_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        self.event_scores.sort_values(by=0, ascending=False, inplace=True)\n",
    "        \n",
    "        self.predict_season_scores(season_scores)\n",
    "\n",
    "    def evaluate_rmse_over_years(self, years, season_df, world_df, **kwargs):\n",
    "        rmses = []\n",
    "        for year in years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            self.fit(season_scores, **kwargs)\n",
    "            rmse = self.evaluate_rmse(season_scores)\n",
    "            rmses.append(rmse)\n",
    "        return pd.DataFrame({'year': years, 'rmse': rmses}).sort_values(by='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=10)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Yuzuru, HANYU</th>\n",
       "      <td>9.311300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nathan, CHEN</th>\n",
       "      <td>7.737974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Javier, FERNANDEZ</th>\n",
       "      <td>7.563217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoma, UNO</th>\n",
       "      <td>7.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patrick, CHAN</th>\n",
       "      <td>6.425772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "Yuzuru, HANYU      9.311300\n",
       "Nathan, CHEN       7.737974\n",
       "Javier, FERNANDEZ  7.563217\n",
       "Shoma, UNO         7.491667\n",
       "Patrick, CHAN      6.425772"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.skater_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EU</th>\n",
       "      <td>11.307682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4C</th>\n",
       "      <td>10.576126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RU</th>\n",
       "      <td>9.723993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CN</th>\n",
       "      <td>9.441479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FR</th>\n",
       "      <td>8.758149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "EU  11.307682\n",
       "4C  10.576126\n",
       "RU   9.723993\n",
       "CN   9.441479\n",
       "FR   8.758149"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid.event_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train over all years in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>rmse</th>\n",
       "      <th>tau</th>\n",
       "      <th>conc</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005</td>\n",
       "      <td>9.608030</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>171</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006</td>\n",
       "      <td>9.165213</td>\n",
       "      <td>0.620553</td>\n",
       "      <td>205</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007</td>\n",
       "      <td>7.982004</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>227</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>8.743461</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>221</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>10.162420</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>197</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012</td>\n",
       "      <td>8.995002</td>\n",
       "      <td>0.612648</td>\n",
       "      <td>204</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>9.202840</td>\n",
       "      <td>0.644269</td>\n",
       "      <td>208</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>9.472834</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>192</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>11.426683</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>233</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>9.541887</td>\n",
       "      <td>0.688406</td>\n",
       "      <td>233</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       rmse       tau  conc  pairs\n",
       "0  2005   9.608030  0.628571   171    210\n",
       "1  2006   9.165213  0.620553   205    253\n",
       "2  2007   7.982004  0.644928   227    276\n",
       "3  2009   8.743461  0.601449   221    276\n",
       "4  2010  10.162420  0.705628   197    231\n",
       "5  2012   8.995002  0.612648   204    253\n",
       "6  2013   9.202840  0.644269   208    253\n",
       "7  2014   9.472834  0.828571   192    210\n",
       "8  2016  11.426683  0.688406   233    276\n",
       "9  2017   9.541887  0.688406   233    276"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=10)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6757500470543949"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.798979360662049 0.6695765104460756\n",
      "0.1 8.799759095040118 0.670301148127235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-35365a373ecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhybrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHybrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_factors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n\u001b[0;32m----> 4\u001b[0;31m                                                    n_iter=1000, seed=42)\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_train_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rmse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhybrid_train_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tau'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-67a0aaa44317>\u001b[0m in \u001b[0;36mevaluate_over_years\u001b[0;34m(self, years, season_df, world_df, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mseason_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_yearly_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseason_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcordant_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kendall_tau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-45b353a177f4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, season_scores, n_iter, seed, fixed_baseline, verbose)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mskater_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskater_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mevent_gradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnansum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskater_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'skater_gradients\\n{skater_gradients}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'event_gradients\\n{event_gradients}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray_str\u001b[0;34m(a, max_line_width, precision, suppress_small)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_guarded_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_line_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuppress_small\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mset_string_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, **kwarg)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    459\u001b[0m     lst = _formatArray(a, format_function, options['linewidth'],\n\u001b[1;32m    460\u001b[0m                        \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edgeitems'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m                        summary_insert, options['legacy'])\n\u001b[0m\u001b[1;32m    462\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[0m\n\u001b[1;32m    759\u001b[0m         return recurser(index=(),\n\u001b[1;32m    760\u001b[0m                         \u001b[0mhanging_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                         curr_width=line_width)\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;31m# recursive closures have a cyclic reference to themselves, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrailing_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hanging_indent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m                 s, line = _extendLine(\n\u001b[1;32m    717\u001b[0m                     s, line, word, elem_width, hanging_indent, legacy)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxes_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformat_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# when recursing, add a space to align with the [ added, and reduce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                       \u001b[0msign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                                       \u001b[0mpad_left\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_left\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m                                       pad_right=self.pad_right)\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[0;31m# for back-compatibility, we keep the classes for each float type too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lambda_reg in [0, 0.1, 1, 2, 5, 10]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                                                   n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_train_eval['rmse'].mean(), hybrid_train_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = Hybrid(alpha=0.001, n_factors=1, lambda_reg=1)\n",
    "hybrid.fit(season_scores, n_iter=1000, seed=42)\n",
    "hybrid_train_eval = hybrid.evaluate_over_years(train_years, season_train, world_train, \n",
    "                    n_iter=1000, seed=42)\n",
    "hybrid_train_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambda_reg in [0, 1]:\n",
    "    hybrid = Hybrid(lambda_reg=lambda_reg, alpha=0.001, n_factors=1)\n",
    "    hybrid_test_eval = hybrid.evaluate_over_years(test_years, season_test, world_test,\n",
    "                                                  n_iter=1000, seed=42)\n",
    "    print(lambda_reg, hybrid_test_eval['rmse'].mean(), hybrid_test_eval['tau'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = AverageScore()\n",
    "avg_test_eval = avg.evaluate_over_years(test_years, season_test, world_test)\n",
    "avg_test_eval['tau'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(seed=42)\n",
    "f1_years = list(random_state.choice(train_years, 5, replace=False))\n",
    "f2_years = [year for year in train_years if year not in f1_years]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_and_world_scores(scores):\n",
    "    all_season_scores = {}\n",
    "    all_world_scores = {}\n",
    "\n",
    "    for year in range(2005, 2020):\n",
    "        season_scores = scores.loc[(scores['year']==year) & (scores['event']!='WR')].copy()\n",
    "        world_scores = scores.loc[(scores['year']==year) & (scores['event']=='WR'), ['name', 'score']]\n",
    "        world_scores = world_scores.set_index('name').squeeze()\n",
    "        all_season_scores[year] = season_scores\n",
    "        all_world_scores[year] = world_scores\n",
    "    return all_season_scores, all_world_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_season_scores, all_world_scores = get_season_and_world_scores(male_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_normalized_scores = {}\n",
    "all_pair_diffs = {}\n",
    "\n",
    "for year in train_years:\n",
    "    season_scores = all_season_scores[year]\n",
    "    world_scores = all_world_scores[year]\n",
    "    hybrid = Hybrid(alpha=0.001, n_factors=5, lambda_reg=10)\n",
    "    hybrid.fit(season_scores, n_iter=1000, seed=42)    \n",
    "    hybrid_scores = hybrid.skater_scores\n",
    "    \n",
    "    normalized_scores = (hybrid_scores - hybrid_scores.mean(axis=0)) / hybrid_scores.std(axis=0)\n",
    "    normalized_scores = normalized_scores.reindex(world_scores.index).dropna()\n",
    "    all_normalized_scores[year] = normalized_scores\n",
    "    \n",
    "    pair_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normalized_scores.values, 2)))\n",
    "    all_pair_diffs[year] = pair_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack((all_pair_diffs[year] for year in f2_years))\n",
    "y_train = np.full(len(X_train), 1)\n",
    "n_coefs = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37336036, 0.80010816, 0.25238218, 0.38409724, 0.50886353])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = BatchLogistic(theta=np.full(n_coefs, 0.5), alpha=0.001, lambda_reg=10)\n",
    "log.fit(X_train, y_train, n_iter=1000)\n",
    "log.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "There are 237 concordant_pairs out of 276 pairs\n",
      "2006\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "2012\n",
      "There are 199 concordant_pairs out of 253 pairs\n",
      "2005\n",
      "There are 173 concordant_pairs out of 210 pairs\n",
      "2014\n",
      "There are 191 concordant_pairs out of 210 pairs\n",
      "0.6755467720685113\n"
     ]
    }
   ],
   "source": [
    "f1_taus = []\n",
    "for year in f1_years:\n",
    "    print(year)\n",
    "    normalized_scores = all_normalized_scores[year]\n",
    "    combined_scores =  pd.Series(normalized_scores @ log.theta, index=normalized_scores.index)\n",
    "    combined_ranking, world_ranking = return_ranking(combined_scores, all_world_scores[year])\n",
    "    f1_taus.append(calculate_kendall_tau(combined_ranking, world_ranking))\n",
    "    \n",
    "print(np.array(f1_taus).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      "There are 228 concordant_pairs out of 276 pairs\n",
      "2009\n",
      "There are 223 concordant_pairs out of 276 pairs\n",
      "2010\n",
      "There are 195 concordant_pairs out of 231 pairs\n",
      "2013\n",
      "There are 202 concordant_pairs out of 253 pairs\n",
      "2017\n",
      "There are 226 concordant_pairs out of 276 pairs\n",
      "0.638189346884999\n"
     ]
    }
   ],
   "source": [
    "f2_taus = []\n",
    "for year in f2_years:\n",
    "    print(year)\n",
    "    normalized_scores = all_normalized_scores[year]\n",
    "    combined_scores =  pd.Series(normalized_scores @ log.theta, index=normalized_scores.index)\n",
    "    combined_ranking, world_ranking = return_ranking(combined_scores, all_world_scores[year])\n",
    "    f2_taus.append(calculate_kendall_tau(combined_ranking, world_ranking))\n",
    "    \n",
    "print(np.array(f2_taus).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refactoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridLog:\n",
    "    def __init__(self, n_factors, hybrid_lambda,\n",
    "              hybrid_alpha=0.001, hybrid_iter=1000, hybrid_seed=42,\n",
    "              log_alpha=0.001, log_iter=1000):\n",
    "        self.n_factors = n_factors\n",
    "        self.hybrid_lambda = hybrid_lambda\n",
    "        self.hybrid_alpha = hybrid_alpha\n",
    "        self.hybrid_iter = hybrid_iter\n",
    "        self.hybrid_seed = hybrid_seed\n",
    "        self.log_alpha = log_alpha\n",
    "        self.log_iter = log_iter\n",
    "\n",
    "    \n",
    "    def fit_hybrid(self, season_df, world_df, train_years):\n",
    "        # Train hybrid model on each training years to get latent factor values\n",
    "        all_pair_diffs = {}\n",
    "        for year in train_years:\n",
    "            season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "            hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "            hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed)\n",
    "            hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "            normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)\n",
    "            normalized_scores = normalized_scores.reindex(world_scores.index).dropna()\n",
    "\n",
    "            pair_diffs = np.array(list(skater1 - skater2 for skater1, skater2 in combinations(normalized_scores.values, 2)))\n",
    "            all_pair_diffs[year] = pair_diffs\n",
    "\n",
    "        # Train logistic regression on pairwise differences of latent factor values\n",
    "        self.X_train = np.vstack((all_pair_diffs[year] for year in train_years))\n",
    "        self.y_train = np.full(len(self.X_train), 1)\n",
    "    \n",
    "    \n",
    "    def fit_log(self, log_lambda):\n",
    "        log = BatchLogistic(theta=np.full(self.n_factors, 0.5), alpha=self.log_alpha, \n",
    "                            lambda_reg=log_lambda)\n",
    "        log.fit(self.X_train, self.y_train, n_iter=self.log_iter)\n",
    "        self.log_coefs = log.theta\n",
    "\n",
    "    \n",
    "    def predict(self, season_scores):\n",
    "        hybrid = Hybrid(alpha=self.hybrid_alpha, n_factors=self.n_factors, lambda_reg=self.hybrid_lambda)\n",
    "        hybrid.fit(season_scores, n_iter=self.hybrid_iter, seed=self.hybrid_seed)    \n",
    "        hybrid_skater_scores = hybrid.skater_scores\n",
    "\n",
    "        normalized_scores = (hybrid_skater_scores - hybrid_skater_scores.mean(axis=0)) / hybrid_skater_scores.std(axis=0)    \n",
    "        combined_scores = pd.Series(normalized_scores @ self.log_coefs, index=normalized_scores.index)\n",
    "        combined_scores.sort_values(ascending=False, inplace=True)\n",
    "        return combined_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_kendall_tau(hybridlog, years, season_df, world_df):\n",
    "    kendall_taus = []\n",
    "    for year in years:\n",
    "        season_scores, world_scores = get_yearly_scores(year, season_df, world_df)\n",
    "        combined_scores = hybridlog.predict(season_scores)\n",
    "        combined_ranking, world_ranking = return_ranking(combined_scores, world_scores)\n",
    "        kendall_tau = calculate_kendall_tau(combined_ranking, world_ranking, verbose=False)\n",
    "        kendall_taus.append(kendall_tau)\n",
    "\n",
    "    return np.array(kendall_taus).mean()\n",
    "\n",
    "\n",
    "def get_tau_train_val(season_df, world_df, train_years, val_years,\n",
    "                      hybridlog, log_lambda):\n",
    "    hybridlog.fit_log(log_lambda)\n",
    "    avg_tau_train = average_kendall_tau(hybridlog, train_years, season_df, world_df)\n",
    "    avg_tau_val = average_kendall_tau(hybridlog, val_years, season_df, world_df)\n",
    "    return avg_tau_train, avg_tau_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_factor: 1, hybrid_lambda: 10, log_lambda: 10\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "There are 204 concordant_pairs out of 253 pairs\n",
      "There are 171 concordant_pairs out of 210 pairs\n",
      "There are 192 concordant_pairs out of 210 pairs\n",
      "There are 227 concordant_pairs out of 276 pairs\n",
      "There are 221 concordant_pairs out of 276 pairs\n",
      "There are 197 concordant_pairs out of 231 pairs\n",
      "There are 208 concordant_pairs out of 253 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 227 concordant_pairs out of 276 pairs\n",
      "There are 221 concordant_pairs out of 276 pairs\n",
      "There are 197 concordant_pairs out of 231 pairs\n",
      "There are 208 concordant_pairs out of 253 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 233 concordant_pairs out of 276 pairs\n",
      "There are 205 concordant_pairs out of 253 pairs\n",
      "There are 204 concordant_pairs out of 253 pairs\n",
      "There are 171 concordant_pairs out of 210 pairs\n",
      "There are 192 concordant_pairs out of 210 pairs\n",
      "f1_train: 0.6757500470543949, f1_val: 0.656935817805383, f2_train: 0.656935817805383, f2_val: 0.6757500470543949\n"
     ]
    }
   ],
   "source": [
    "n_factors = []\n",
    "hybrid_lambdas = []\n",
    "log_lambdas = []\n",
    "f1_tau_trains = []\n",
    "f1_tau_vals = []\n",
    "f2_tau_trains = []\n",
    "f2_tau_vals = []\n",
    "\n",
    "n_iter = 1000\n",
    "for n_factor in [1, ]:\n",
    "    for hybrid_lambda in [10]:\n",
    "        n_factors.append(n_factor)\n",
    "        hybrid_lambdas.append(hybrid_lambda)\n",
    "\n",
    "        # Train hybrid models on each fold\n",
    "        hybridlog1 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter)\n",
    "        hybridlog1.fit_hybrid(season_male, world_male, f1_years)\n",
    "\n",
    "        hybridlog2 = HybridLog(n_factors=n_factor, hybrid_lambda=hybrid_lambda,\n",
    "                            hybrid_alpha=0.001, hybrid_iter=n_iter, hybrid_seed=42,\n",
    "                            log_alpha=0.001, log_iter=n_iter)\n",
    "        hybridlog2.fit_hybrid(season_male, world_male, f2_years)\n",
    "\n",
    "      # Train log models on each fold and evaluate kendall tau\n",
    "    for log_lambda in [10]:\n",
    "        print(f'n_factor: {n_factor}, hybrid_lambda: {hybrid_lambda}, log_lambda: {log_lambda}')\n",
    "        log_lambdas.append(log_lambda)\n",
    "        f1_tau_train, f1_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f1_years, f2_years,\n",
    "                                                     hybridlog1, log_lambda)\n",
    "        f2_tau_train, f2_tau_val = get_tau_train_val(season_male, world_male,\n",
    "                                                     f2_years, f1_years,\n",
    "                                                     hybridlog2, log_lambda)\n",
    "        print(f'f1_train: {f1_tau_train}, f1_val: {f1_tau_val}, f2_train: {f2_tau_train}, f2_val: {f2_tau_val}')\n",
    "        f1_tau_trains.append(f1_tau_train)\n",
    "        f1_tau_vals.append(f1_tau_val)\n",
    "        f2_tau_trains.append(f2_tau_train)\n",
    "        f2_tau_vals.append(f2_tau_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_factor</th>\n",
       "      <th>hybrid_lambda</th>\n",
       "      <th>log_lambda</th>\n",
       "      <th>f1_tau_train</th>\n",
       "      <th>f1_tau_val</th>\n",
       "      <th>f2_tau_train</th>\n",
       "      <th>f2_tau_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.67575</td>\n",
       "      <td>0.656936</td>\n",
       "      <td>0.656936</td>\n",
       "      <td>0.67575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_factor  hybrid_lambda  log_lambda  f1_tau_train  f1_tau_val  \\\n",
       "0         1             10          10       0.67575    0.656936   \n",
       "\n",
       "   f2_tau_train  f2_tau_val  \n",
       "0      0.656936     0.67575  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparisons = pd.DataFrame({'n_factor': n_factors, 'hybrid_lambda': hybrid_lambdas, 'log_lambda': log_lambdas,\n",
    "'f1_tau_train': f1_tau_trains, 'f1_tau_val': f1_tau_vals,\n",
    "'f2_tau_train': f2_tau_trains, 'f2_tau_val': f2_tau_vals})\n",
    "comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.656935817805383"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_train_eval.loc[hybrid_train_eval['year'].isin(f2_years), 'tau'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
